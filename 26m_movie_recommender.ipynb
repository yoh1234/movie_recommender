{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyVlAN4quzHD/uSL/8Wgbk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoh1234/movie_recommender/blob/main/26m_movie_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install surprise"
      ],
      "metadata": {
        "id": "x-zH_MRQaE5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from ast import literal_eval\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from surprise import Reader, Dataset, SVD\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "9TYkh9zHZ-N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmAz7XDO3L2R"
      },
      "outputs": [],
      "source": [
        "# !apt-get update # Update apt-get repository.\n",
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null # Install Java.\n",
        "# !wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz # Download Apache Sparks.\n",
        "# !tar xf spark-3.1.1-bin-hadoop3.2.tgz # Unzip the tgz file.\n",
        "# !pip install -q findspark # Install findspark. Adds PySpark to the System path during runtime.\n",
        "\n",
        "# # Set environment variables\n",
        "# import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "# !ls\n",
        "\n",
        "# # Initialize findspark\n",
        "# import findspark\n",
        "# findspark.init()\n",
        "\n",
        "# # Create a PySpark session\n",
        "# from pyspark.sql import SparkSession\n",
        "# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spark"
      ],
      "metadata": {
        "id": "bqE9iXTJ38Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aOgR7v5ETGIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_movies = pd.read_csv('/content/drive/My Drive/26m_movie/movies_metadata.csv')\n",
        "df_movies.head()"
      ],
      "metadata": {
        "id": "JrRAfmyuWVxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies = df_movies[df_movies[\"adult\"] == \"False\"]\n",
        "print(len(df_movies))"
      ],
      "metadata": {
        "id": "Jvecdl_uYR-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_only_lists_col1 = df_movies['genres'].apply(lambda x: isinstance(x, list)).all()\n",
        "print(f\"Does 'col1' contain only lists? {is_only_lists_col1}\")"
      ],
      "metadata": {
        "id": "iSpL3MgwhxaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if genres column contains list type data\n",
        "df_check_genres_datatype = df_movies['genres'].apply(lambda x: isinstance(literal_eval(x), list))\n",
        "df_check_genres_datatype = pd.DataFrame(df_check_genres_datatype)\n",
        "count = len(df_check_genres_datatype[df_check_genres_datatype[\"genres\"] == True])\n",
        "print(count)\n"
      ],
      "metadata": {
        "id": "feURPdTqiPxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies['genres'] = df_movies['genres'].apply(literal_eval).apply(lambda x:\n",
        " [i['name'] for i in x])"
      ],
      "metadata": {
        "id": "e9P4qQcqaJPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_year(x):\n",
        "  return x.split('-')[0]\n"
      ],
      "metadata": {
        "id": "zNJDTVDL9qjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies['release_date'] = df_movies['release_date'].astype(str)\n",
        "df_movies['year'] = df_movies['release_date'].apply(extract_year)\n",
        "df_movies\n"
      ],
      "metadata": {
        "id": "QNP0LxrbaCCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df_movies['original_language'].nunique())"
      ],
      "metadata": {
        "id": "u_uR3fHlxo1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Count the number of movies based on languages\n",
        "# language_count = df_movies.groupby('original_language')['id'].count().reset_index(name='count')\n",
        "# language_count = language_count.sort_values('count', ascending=False)\n",
        "# print(language_count.head(20))"
      ],
      "metadata": {
        "id": "kP49QuMDxzy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_movies = df_movies[df_movies['original_language'] == 'en']\n",
        "# print(len(df_movies))"
      ],
      "metadata": {
        "id": "E_EdXsogzXJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate weighted rating from IMDB's weighted rating formula\n",
        "# v/(v+m)*R + m/(v+m)*C\n",
        "df_movies['vote_count'].isnull().sum()"
      ],
      "metadata": {
        "id": "JI_0hS5TasUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies = df_movies.dropna(subset=['vote_count'])\n",
        "print(len(df_movies))"
      ],
      "metadata": {
        "id": "SVFiClZJnbWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies['vote_average'].isnull().sum()"
      ],
      "metadata": {
        "id": "lmaCbh6joJxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_subset(list1, list2):\n",
        "  if set(list1).issubset(set(list2)):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "Sx6xWUeF7u5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_rating(x, m, C):\n",
        "    v = x['vote_count']\n",
        "    R = x['vote_average']\n",
        "    return (v/(v+m) * R) + (m/(m+v) * C)"
      ],
      "metadata": {
        "id": "YDyG-zZQK72o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_qualified_dataset(df_genre, genre = None, percentile = 0.95, use_all_genre = False):\n",
        "  if use_all_genre:\n",
        "    df_genre = df_genre\n",
        "  else:\n",
        "    df_genre['genre_selected'] = df_genre['genres'].apply(lambda x: check_subset(genre, x))\n",
        "    df_genre = df_genre[df_genre['genre_selected']]\n",
        "  C = df_genre['vote_average'].mean()\n",
        "  m = df_genre['vote_count'].quantile(percentile)\n",
        "  print(m)\n",
        "\n",
        "  df_genre_qualified = df_genre[df_genre['vote_count'] >= m][['title', 'year', 'vote_count', 'vote_average', 'popularity', 'id','genres']]\n",
        "  df_genre_qualified['wr'] = df_genre_qualified.apply(lambda x: weighted_rating(x, m, C), axis=1)\n",
        "  df_genre_qualified = df_genre_qualified.sort_values('wr', ascending=False)\n",
        "  return df_genre_qualified"
      ],
      "metadata": {
        "id": "n1oFb3LsJY4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_qualified_dataset(df_movies, ['Animation']).head(20)"
      ],
      "metadata": {
        "id": "y1H-smZ1Jeme",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get qualified movie dataset\n",
        "df_movies_qualified = get_qualified_dataset(df_movies, use_all_genre = True)\n",
        "print(len(df_movies_qualified))"
      ],
      "metadata": {
        "id": "0QLeMZxSvgwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies_qualified.head(20)"
      ],
      "metadata": {
        "id": "abrN0BgPxN0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use qualified data only\n",
        "df_movies = df_movies_qualified"
      ],
      "metadata": {
        "id": "lYskZOgHxHYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content Based Recommender"
      ],
      "metadata": {
        "id": "_6gHoc5zSH5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_link = pd.read_csv('/content/drive/My Drive/26m_movie/links.csv')\n",
        "df_link.head()"
      ],
      "metadata": {
        "id": "kPB231BrCgAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_link = df_link[df_link['tmdbId'].notnull()]"
      ],
      "metadata": {
        "id": "pXEX3EGqSWsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_link['tmdbId'] = df_link['tmdbId'].astype('int')"
      ],
      "metadata": {
        "id": "mrH6P8HUTIkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_link.info()"
      ],
      "metadata": {
        "id": "r8YqDDyxShYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_link_unique = df_link.drop_duplicates(subset=['movieId'])"
      ],
      "metadata": {
        "id": "v3VGaD1ZTle7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_link['check_missing_values'] = df_link['tmdbId'].apply(lambda x: True if str(x) in df_movies['id'].values else False)"
      ],
      "metadata": {
        "id": "6OJ2O3uyUKZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_link.info()"
      ],
      "metadata": {
        "id": "smaP9mwMUoa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_link = df_link[df_link['check_missing_values']]"
      ],
      "metadata": {
        "id": "aCg0lxzNU1oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_link))\n",
        "print(len(df_movies))"
      ],
      "metadata": {
        "id": "TLdNIj_IUp3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_link.head()"
      ],
      "metadata": {
        "id": "DKm5e7rVUt-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movie = df"
      ],
      "metadata": {
        "id": "E-mzCRGpZdK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Movie Description Based Recommender"
      ],
      "metadata": {
        "id": "KD3-C_jjZNnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_movie['tagline'] = df_movie['tagline'].fillna('')\n",
        "df_movie['description'] = df_movie['overview'] + df_movie['tagline']\n",
        "df_movie['description'] = df_movie['description'].fillna('')"
      ],
      "metadata": {
        "id": "Gi6ETc89ZODx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=1, stop_words='english', max_features=100)\n",
        "# tfidf_matrix = tf.fit_transform(df_movie['description'])"
      ],
      "metadata": {
        "id": "ANH49N2GZVEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf_matrix.shape"
      ],
      "metadata": {
        "id": "bxEEx7HMZu4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "# cosine_sim"
      ],
      "metadata": {
        "id": "r-mZXJKpZwtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "oEahvEyiMNpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"CosineSimilarityLargeData\").getOrCreate()"
      ],
      "metadata": {
        "id": "zdR0Gq6IcGnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType\n",
        "import numpy as np\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# Define the schema explicitly for the 'vector' column as an array of floats\n",
        "schema = StructType([\n",
        "    StructField(\"id\", FloatType(), False),\n",
        "    StructField(\"features\", ArrayType(FloatType()), False)  # The vector is an array of floats\n",
        "])\n",
        "\n",
        "# Generate large random data (for example purposes)\n",
        "num_rows = 100  # Simulate 10,000 vectors (adjust this based on your memory constraints)\n",
        "vector_size = 100  # Each vector will have 100 features\n",
        "\n",
        "# Create random vectors as lists (not numpy arrays)\n",
        "data = []\n",
        "for i in range(num_rows):\n",
        "    vector = np.random.rand(vector_size).tolist()  # Convert numpy array to list\n",
        "    data.append(Row(id=float(i), vector=vector))\n",
        "\n",
        "# Create a DataFrame using the schema\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# Show the first few rows\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "jUF2tJ_kVID5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_partitioned = df.repartition(100)"
      ],
      "metadata": {
        "id": "5Sj9_IGQQV0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_partitioned.show(5)"
      ],
      "metadata": {
        "id": "kMT9oquFQWUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(2)"
      ],
      "metadata": {
        "id": "grc3ZhsBqwhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF\n",
        "hashingTF = HashingTF(inputCol=\"features\", outputCol=\"tf\")\n",
        "tf = hashingTF.transform(df)\n",
        "\n",
        "idf = IDF(inputCol=\"tf\", outputCol=\"feature\").fit(tf)\n",
        "tfidf = idf.transform(tf)"
      ],
      "metadata": {
        "id": "GR9erOnL8h3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Normalizer\n",
        "normalizer = Normalizer(inputCol=\"feature\", outputCol=\"norm\")\n",
        "data = normalizer.transform(tfidf)"
      ],
      "metadata": {
        "id": "RW-musbs81Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
        "mat = IndexedRowMatrix(\n",
        "    data.select(\"ID\", \"norm\")\\\n",
        "        .rdd.map(lambda row: IndexedRow(row.ID, row.norm.toArray()))).toBlockMatrix()\n",
        "dot = mat.multiply(mat.transpose())\n",
        "dot.toLocalMatrix().toArray()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PxmLSHRy9SGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collaborative Filtering"
      ],
      "metadata": {
        "id": "sLZB4D-ruBdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_ratings = pd.read_csv('/content/drive/My Drive/26m_movie/ratings.csv')\n",
        "df_ratings.head()"
      ],
      "metadata": {
        "id": "45sw7DSVuGMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies.head()"
      ],
      "metadata": {
        "id": "JJaQNvBmvlZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies['id'] = df_movies['id'].astype(int)"
      ],
      "metadata": {
        "id": "Zx-Hrm7XxkYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_ratings))"
      ],
      "metadata": {
        "id": "x1OmUcxR6kPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_movies))"
      ],
      "metadata": {
        "id": "fJeDMXDXp2M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies_merged = pd.merge(df_movies, df_link[['movieId', 'tmdbId']], left_on = 'id', right_on = 'tmdbId')"
      ],
      "metadata": {
        "id": "_A8fnrsTsEqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies_merged.head(2)"
      ],
      "metadata": {
        "id": "M5e70q367nz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies_id_set = set(df_movies_merged['movieId'])"
      ],
      "metadata": {
        "id": "MGOCFqR7pbVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_movies_id_set))"
      ],
      "metadata": {
        "id": "Cqbs7siKqLSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings['is_in_qualified_movies'] = df_ratings['movieId'].apply(lambda id: id in df_movies_id_set)"
      ],
      "metadata": {
        "id": "sS9vLpsMpj2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings.head()"
      ],
      "metadata": {
        "id": "2-v0dSaYqHzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_ratings['is_in_qualified_movies'].value_counts())"
      ],
      "metadata": {
        "id": "0g-s0BAq7_pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_qualified = df_ratings[df_ratings['is_in_qualified_movies']]\n",
        "df_ratings_qualified.head()"
      ],
      "metadata": {
        "id": "HbGCqnar7RAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_count = df_ratings_qualified.groupby('userId').size().sort_values(ascending = False)\n",
        "id_count = id_count.reset_index(name='count')\n",
        "print(id_count)"
      ],
      "metadata": {
        "id": "npPpUKRtypkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_qualified = pd.merge(df_ratings_qualified, id_count, on = 'userId', how = 'left')"
      ],
      "metadata": {
        "id": "Wq1CVmpO0_Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_qualified"
      ],
      "metadata": {
        "id": "2su5DndP1iWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_qualified = df_ratings_qualified[df_ratings_qualified['count'] >= 10]"
      ],
      "metadata": {
        "id": "z4II0Za21OnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_ratings_qualified))"
      ],
      "metadata": {
        "id": "Ol5gX7tRzR_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ratings_qualified = df_ratings_qualified[['userId', 'movieId', 'rating']]\n",
        "df_ratings_qualified.head()"
      ],
      "metadata": {
        "id": "Px7LBK7R2CbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader()"
      ],
      "metadata": {
        "id": "Hv8NjRlt2ZpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset.load_from_df(df_ratings_qualified, reader)"
      ],
      "metadata": {
        "id": "n_KZDz7O2d3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy"
      ],
      "metadata": {
        "id": "MYlnebLZ3R5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.25)"
      ],
      "metadata": {
        "id": "q3k6o11W3QWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1Oew-bvLzPEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SVD()\n",
        "\n",
        "# Step 3: Train the model on the training set\n",
        "model.fit(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd2BxWny2lFm",
        "outputId": "6655c5f4-b934-4c8b-d7f9-bf68027e3a96"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x78a7847130d0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.test(testset)"
      ],
      "metadata": {
        "id": "pgXwm2-r8pIm"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = accuracy.rmse(predictions)\n",
        "print(f\"RMSE on the Test Set: {rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5RTKhP6--aI",
        "outputId": "54600250-3bae-4fc9-92ec-ea38dfb62090"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.7855\n",
            "RMSE on the Test Set: 0.7855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('svd_first_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(\"Model saved successfully to 'svd_model.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX44c-sP_y4p",
        "outputId": "cf6a9c17-4fa4-463b-84b2-8be563bad05d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully to 'svd_model.pkl'\n"
          ]
        }
      ]
    }
  ]
}